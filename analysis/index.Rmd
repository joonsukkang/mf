---
title: "Home"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---


# alternating flash

### binary toy data


:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}

:::
::: {}
+ binary toy data
  + [data](https://raw.githubusercontent.com/joonsukkang/mf/master/data/binary_toy.rds)
  + [script and SVD](create_binary_toy.html)


:::
::::

  

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/binary_toy_nonneg_pe.Rmd/unnamed-chunk-6-2.png" width="400">
:::
::: {}
+ [altflash: nonneg init + point-exponential prior](binary_toy_nonneg_pe.html) on binary toy data
  + nonneg init: too many factors estimated (false signals captured)
  + oracle init: some factors dropped (true signals lost)
  + elbo: nonneg init > oracle init
  + if the true $L$ is (close to) binary, binary prior seems beneficial


:::
::::




:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/binary_toy_ncut.Rmd/unnamed-chunk-7-9.png">
:::
::: {}
    

+ [NCut](binary_toy_ncut.html)
  + NCut outperforms hierarchical clustering with complete linkage
  + even with noisier version (factors 1-8), NCut successfully finds the structure
  + Like hclust, NCut assumes a nested structure: we can find a tree, but not a general overlapping structure

:::
::::



:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/binary_toy_hclust.Rmd/unnamed-chunk-3-3.png" width="400">
:::
::: {}
    

+ [hierarchical clustering](binary_toy_hclust.html)
  + using denoised (soft-thresholding, factors 2-8) matrix, hierarhical clustering with complete linkage easily uncovers the structure
  + but if we include the factor 1, the method fails

:::
::::



:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/binary_toy_denoising.Rmd/unnamed-chunk-8-3.png" width="400">
:::
::: {}
    
+ [denoising](binary_toy_denoising.html)
  + by soft thresholding eigenvalues and dropping the leading factor, we can successfully denoise XX'
  + our key matrix XX'=(LF'+E)(LF'+E)'=LF'FL'+LF'E'+EFL'+EE'
  + "soft thresholding": the term EE' in XX' is close to $p\sigma^2I_n$, so the diagonal terms of XX' are disproportionately big; we can use soft thresholding eigenvalues to solve the issue
  + "dropping the leading factor": the term LF'E'+EFL' blurs the pattern observed in the true data; dropping the first factor $\lambda_1u_1u_1^T$ ($u_1$ is close to a constant) solves the issue


:::
::::



### Yusha's toy data


:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://raw.githubusercontent.com/joonsukkang/mf/master/docs/figure/toy_Yusha_nonneg_1.Rmd/unnamed-chunk-8-2.png" width="400">
:::
::: {}
+ [altflash on Yusha's toy data](toy_Yusha_nonneg_1.html)
  + method
    + initialize nonnegative $L$ matrix using eigenvectors of $XX^T$
    + use point-exponential family as prior family
  + results
    + the result is interpretable in that it returns the 11 factors
    + the elbo is lower than the result with oracle init (in which the pattern is less visible, though)
    

+ More on the toy data
  + [svd of toy data by Yusha](toy_Yusha_svd.html)
  + [oracle init of toy data by Yusha](toy_Yusha_oracle.html)


:::
::::

### original tree toy data


:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/tree_toy_altflash_1.Rmd/unnamed-chunk-14-2.png" width="400">
:::
::: {}
+ [altflash on tree toy data](tree_toy_altflash_1.html)
  + method
    + priors are set as point-exponential: $0.1\delta_0(\cdot)+0.9\exp(\cdot; \lambda=1)$
    + two-step procedure is implemented. 
      + the first step is to stabilize the fit given `g.l,g.f`
      + the second step is to fully update (including `g.l,g.f`)
    + use denoised (rank-2) `XX^T/p`
  + results
    + all four patterns `(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)` are captured when $K\geq4$
    + when $K<4$, only $K$ of the four patterns are captured
    + posterior mean of $L$ and $F$ are symmetric (up to scale)

:::
::::



:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/tree_toy_flashier_denoising.Rmd/unnamed-chunk-8-2.png" width="400">
:::
::: {}
+ [but first, denoising](tree_toy_flashier_denoising.html)
  + the goal is to extract `(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)` and we use flashier on `XX^T/p` with point-exponential prior
  + with the (apparent) rank-2 plus noise structure of toy data, we can greatly improve the fit by using the rank-2 version of the data matrix as the input
  + three of the four patterns are captures in `X2`, `X2n_a`; two in `X2n_b`
  + there are still one or two patterns that are not found

:::
::::








:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://raw.githubusercontent.com/joonsukkang/mf/master/docs/figure/tree_toy_flashier.Rmd/unnamed-chunk-10-1.png" width="400">
:::
::: {}
+ [flashier on tree toy data](tree_toy_flashier.html): as a motivation for alternating flash
  + we could extract `(1,-1,0,0), (0,0,1,-1)` pattern with flashier on `XX^T/p`
  + however, extracting `(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)` seems harder. flashier on `XX^T/p` with point-exponential prior finds only a subset of the signals.
  

+ [minimal](alt-flash-sanity.html): a sanity check for the new minimally functional version of alt-flash


:::
::::



# integrating f out



:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/demo5_model_exp_or_expmix.Rmd/unnamed-chunk-20-1.png" width="400">
:::
::: {}
+ [demo5](demo5_model_exp_or_expmix.html): exponential or exponential mixture prior


:::
::::


# miscellaneous

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/rank1_setup.Rmd/unnamed-chunk-7-1.png" width="400">
:::
::: {}
+ the rank-1 problem: [rank1_setup](rank1_setup.html)
  + The rank-1 problem is stated and the previous and a few additional analyses are shown.
:::
::::

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/warmstart.Rmd/unnamed-chunk-7-1.png" width="400">
:::
::: {}

+ investigation of warmstart advantage  : [warmstart](warmstart.html)
  + The warmstart advantage of `flash` disappears when we restrict to rank-1 approximation.

:::
::::

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/flashier_point_laplace.Rmd/unnamed-chunk-4-1.png" width="400">
:::
::: {}

+ `flashier` result on toy data with point laplace prior : [flashier_point_laplace](flashier_point_laplace.html)
  + When point Laplace prior is put on $L$ and `warmstart` is used, flashier works well.

:::
::::



# archive
:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
:::
::: {}

+ [demo4](model_exp_mixture_prior.html): exponential mixture prior (fixed)
+ [demo3](model_exp_prior.html): exponential prior (fixed)
+ [demo2](demo2_toy.html): sparse binary prior (fixed)
+ [demo1](demo_toy.html) with general discrete prior


:::
::::


