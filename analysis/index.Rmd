---
title: "Home"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---


## alternating flash

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/tree_toy_altflash_1.Rmd/unnamed-chunk-14-2.png" width="400">
:::
::: {}
+ [altflash on tree toy data](tree_toy_altflash_1.html)
  + method
    + priors are set as point-exponential: $0.1\delta_0(\cdot)+0.9\exp(\cdot; \lambda=1)$
    + two-step procedure is implemented. 
      + the first step is to stabilize the fit given `g.l,g.f`
      + the second step is to fully update (including `g.l,g.f`)
    + use denoised (rank-2) data
  + results
    + all four patterns `(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)` are captured when $K\geq4$
    + when $K<4$, only $K$ of the four patterns are captured
    + posterior mean of $L$ and $F$ are symmetric (up to scale)

:::
::::




:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/tree_toy_flashier_denoising.Rmd/unnamed-chunk-8-2.png" width="400">
:::
::: {}
+ [but first, denoising](tree_toy_flashier_denoising.html)
  + the goal is to extract `(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)` and we use flashier on `cov(t(X))` with point-exponential prior
  + with the (apparent) rank-2 plus noise structure of toy data, we can greatly improve the fit by using the rank-2 version of the data matrix as the input
  + three of the four patterns are captures in `X2`, `X2n_a`; two in `X2n_b`
  + there are still one or two patterns that are not found

:::
::::








:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://raw.githubusercontent.com/joonsukkang/mf/master/docs/figure/tree_toy_flashier.Rmd/unnamed-chunk-10-1.png" width="400">
:::
::: {}
+ [flashier on tree toy data](tree_toy_flashier.html): as a motivation for alternating flash
  + we could extract `(1,-1,0,0), (0,0,1,-1)` pattern with flashier on `cov(t(X))`
  + however, extracting `(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)` seems harder. flashier on `cov(t(X))` with point-exponential prior finds only a subset of the signals.
  

+ [minimal](alt-flash-sanity.html): a sanity check for the new minimally functional version of alt-flash


:::
::::



## integrating f out



:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/demo5_model_exp_or_expmix.Rmd/unnamed-chunk-20-1.png" width="400">
:::
::: {}
+ [demo5](demo5_model_exp_or_expmix.html): exponential or exponential mixture prior


:::
::::


## miscellaneous

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/rank1_setup.Rmd/unnamed-chunk-7-1.png" width="400">
:::
::: {}
+ the rank-1 problem: [rank1_setup](rank1_setup.html)
  + The rank-1 problem is stated and the previous and a few additional analyses are shown.
:::
::::

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/warmstart.Rmd/unnamed-chunk-7-1.png" width="400">
:::
::: {}

+ investigation of warmstart advantage  : [warmstart](warmstart.html)
  + The warmstart advantage of `flash` disappears when we restrict to rank-1 approximation.

:::
::::

:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
<img src="https://joonsukkang.github.io/mf/figure/flashier_point_laplace.Rmd/unnamed-chunk-4-1.png" width="400">
:::
::: {}

+ `flashier` result on toy data with point laplace prior : [flashier_point_laplace](flashier_point_laplace.html)
  + When point Laplace prior is put on $L$ and `warmstart` is used, flashier works well.

:::
::::



:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
:::
::: {}

+ [svd of toy data by Yusha](toy_Yusha_svd.html)

:::
::::

## archive
:::: {style="display: flex;"}
::: {style="min-width: 300px; max-width: 300px"}
:::
::: {}

+ [demo4](model_exp_mixture_prior.html): exponential mixture prior (fixed)
+ [demo3](model_exp_prior.html): exponential prior (fixed)
+ [demo2](demo2_toy.html): sparse binary prior (fixed)
+ [demo1](demo_toy.html) with general discrete prior


:::
::::


