---
title: "Tree Toy Data: alt-flash results (1)"
author: "Joonsuk Kang"
date: "2021-10-16"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(flashier)
library(ebnm)
prior.point.exponential <- function(...) {
  args <- as.prior.args(prior.family = "point_exponential",
                        optmethod = "nlm",
                        ...)
  return(do.call(as.prior, args))
}
environment(prior.point.exponential) <- asNamespace('flashier') 
```



# Summary

## Method

* data: denoised (rank-2) data matrix
* priors: point-exponential $0.1\delta_0(\cdot)+0.9\exp(\cdot; \lambda=1)$
* *initialization*: random rank-$K$ initialization
  + first, random rank-$K$ intialization with given priors $g_l,g_f$
  + then, update $q_l, q_f, \tau$ (holding $g_l,g_f$ fixed) until elbo stabilizes 
* backfit using alt-flash: update $q_l$ given $q_f$, and $q_f$ given $q_l$


The initialization seems to play an important role in the model fitting in that 
we need to provide an initial condition for parameters that falls into a feasible reason 
for the alt-flash algorithm to work properly.

I tried a two-step fitting procedure that 

- the first step involves finding a stable state given priors $g_l$ and $g_f$. 
To be specific, we generate initial $L$ from $g_l$ and $F$ from $g_f$, and then
update $q_l, q_f, \tau$ with the priors $g_l,g_f$ fixed, until the ELBO stabilizes.

- the second step is the full backfitting procedure (now start updating $g_l$ and $g_f$ as well). 


This sensitivity to initial conditions does not necessarily mean a sensitivity 
to the prior choices $g_l$ and $g_f$, which needs further investigation.

In the following investigation, we use the following simple point exponential prior 
as the initial values of `g.l` and `g.f`.

```{r}
# a point-exponential prior
g.pe <- gammamix(pi=c(0.1, 0.9), shape=c(1,1), scale=c(0,1))
```


## Results

In all of the cases (`X2`, `X2n_a`, `X2n_b`), all four patterns are captures by the method.

* when $K>4$, only four factors are used and the residual factors are dropped; the desired `(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)` pattern is captured

* when $K<4$, a sub optimal fit is achieved; capturing only $K$ of the four patterns

* we tried five seeds for $K=1,2,\dots,8$; the randomness in seeds has little impact on the results (the only difference would be which $K$ of the four patterns get selected when $K>4$)

* a much higher elbo is achieved compared to flashier (when given $K\geq 4$)

* posterior means of $L$ and $F$ are identical (up to scale) in all cases




# Toy data

```{r}
# code originally from https://stephens999.github.io/misc/tree_pca_03.html.
#--------------------------------------------------
# create X
set.seed(123)
p = 1000
n = 20
f = list()
for(i in 1:6){ 
  f[[i]] = rnorm(p)
}
X =matrix(0,ncol=4*n, nrow=p)
X[,1:(2*n)] = f[[1]]
X[,(2*n+1):(4*n)] = f[[2]]

X[,1:n] = X[,1:n]+f[[3]]
X[,(n+1):(2*n)] = X[,(n+1):(2*n)]+f[[4]]
X[,(2*n+1):(3*n)] = X[,(2*n+1):(3*n)] + f[[5]]
X[,(3*n+1):(4*n)] = X[,(3*n+1):(4*n)] + f[[6]]
X.svd = svd(X)

# create X2
X2 = X- X.svd$u[,1:2] %*% diag(X.svd$d[1:2]) %*% t(X.svd$v[,1:2])

# adding noise
set.seed(9) # the seed where flash didn't work
X2n_a = X2 + rnorm(4*n*p,sd=3)

set.seed(5) # the seed where flash did work
X2n_b = X2 + rnorm(4*n*p,sd=3)
#--------------------------------------------------

# take transpose
X2 <- t(X2)
X2n_a <- t(X2n_a)
X2n_b <- t(X2n_b)

rm(X, X.svd, f, i, n, p)
```


```{r}
# create a rank-2 denoised version of matrix
r2d <- function(dat.mat){
  smat <- svd(dat.mat)
  dmat <- smat$u[,1:2] %*% diag(smat$d[1:2], nrow=2) %*% t(smat$v[,1:2])
  return(dmat)
}

# create a normalized XX^T matrix
XXtn <- function(X){
  X %*% t(X) /ncol(X)
}

# create denoised, normalized XXT matrix
mat2    <- XXtn(r2d(X2))
mat2n_a <- XXtn(r2d(X2n_a))
mat2n_b <- XXtn(r2d(X2n_b))
```


# Some Functions

```{r}
list.to.elbo <- function(out.list){
  
  df <- data.frame(elbo=double(),
                   iteration=integer(),
                   K=integer(),
                   seed=integer())

  for (K in 1:length(out.list)){
    for (seed in 1:length(out.list[[K]])){
      df <- rbind(df, 
                  data.frame(elbo=out.list[[K]][[seed]]$elbo.vec,
                             iteration = 1:length(out.list[[K]][[seed]]$elbo.vec),
                             K=K,
                             seed=seed))
    }
  }
  return(df)
}


list.to.factors <- function(out.list){ 
  
  
  df <- data.frame(L = double(),
                   F = double(),
                   x = integer(),
                   factor = integer(),
                   K = integer(),
                   seed = integer()
                   )
  

  for (K in 1:length(out.list)){
    for (seed in 1:length(out.list[[K]])){
      
      mat.L <- out.list[[K]][[seed]]$A.l # use posterior mean of L
      mat.F <- out.list[[K]][[seed]]$A.f
      
      mat.L <- mat.L %*% diag(1/sqrt(colSums(mat.L^2)),  # scale columns to L2 norm 1
                                    nrow=ncol(mat.L),
                                    ncol=ncol(mat.L))
      mat.F <- mat.F %*% diag(1/sqrt(colSums(mat.F^2)),  # scale columns to L2 norm 1
                                    nrow=ncol(mat.F),
                                    ncol=ncol(mat.F))
      
      df <- rbind(df, 
                  data.frame(L = c(mat.L),
                             F = c(mat.F),
                             x = 1:nrow(mat.L),
                             factor = rep(1:ncol(mat.L), each=nrow(mat.L)),
                             K = K,
                             seed = seed))
    }
  }
  return(df)
}


fig.elbo <-function(out.list){
  list.to.elbo(out.list) %>%
  mutate(seed=as.factor(seed),
         dist=max(elbo)-elbo+1e-6) %>%
  ggplot()+
  geom_line(aes(x=iteration, y=dist, group=seed, col=seed)) +
  scale_y_log10()+
  facet_grid(~K, labeller=labeller(.cols=label_both))+
  ylab('distance from best elbo')
}

fig.L <- function(out.list){
  list.to.factors(out.list) %>% 
  mutate(factor=as.factor(factor)) %>%
  ggplot()+geom_line(aes(x=x, y=L, group=factor, col=factor))+
  facet_grid(K~seed, 
             labeller = labeller(.rows = label_both, .cols = label_both))
}

fig.LF <- function(out.list){
  
  list.to.factors(out.list) %>% 
    mutate(factor=as.factor(factor)) %>%
    ggplot()+geom_line(aes(x=F, y=L, group=factor, col=factor))+
    facet_grid(K~seed, 
               labeller = labeller(.rows = label_both, .cols = label_both)) 
}
```

# Results


```{r}
setwd("~/Box/2-research/mf")
source("code/alt-flash_v20211013.R")
```


## Results: `X2`


```{r, eval=FALSE}
out.list <- list()
data.mat <- mat2

for (K in 1:8){
  print(paste0("now fitting K=",K)) 
  temp.list <- list()
  g.l <- rep(list(g.pe), K)
  g.f <- rep(list(g.pe), K)
      for (seed in 1:5){ 
        temp.list[[seed]] <- alt.flash(Y=data.mat, g.l=g.l, g.f=g.f, seed=seed)
        print(paste0("K=",K, "; seed=", seed, " completed"))
      }
  out.list[[K]] <- temp.list
}

saveRDS(out.list, "output/tree_toy_altflash_mat2_v2021_1012_1309.rds")
```

```{r}
results_mat2 <- readRDS("output/tree_toy_altflash_mat2_v2021_1012_1309.rds")
fig.elbo(results_mat2)
fig.L(results_mat2)
```

```{r}
max(list.to.elbo(results_mat2)$elbo)
flash(mat2, prior.family=prior.point.exponential(), backfit=TRUE, verbose.lvl=0)$elbo
```



## Results: `X2n_a`

```{r, eval=FALSE}
# for record: g.pe <- gammamix(pi=c(0.1, 0.9), shape=c(1,1), scale=c(0,1))
out.list <- list()
data.mat <- mat2n_a

for (K in 1:8){
  print(paste0("now fitting K=",K)) 
  temp.list <- list()
  g.l <- rep(list(g.pe), K)
  g.f <- rep(list(g.pe), K)
      for (seed in 1:5){ 
        temp.list[[seed]] <- alt.flash(Y=data.mat, g.l=g.l, g.f=g.f, seed=seed)
        print(paste0("K=",K, "; seed=", seed, " completed"))
      }
  out.list[[K]] <- temp.list
}

saveRDS(out.list, "output/tree_toy_altflash_mat2n_a_v2021_1012_1309.rds")
```

```{r}
results_mat2n_a <- readRDS("output/tree_toy_altflash_mat2n_a_v2021_1012_1309.rds")
fig.elbo(results_mat2n_a)
fig.L(results_mat2n_a)
```

```{r}
max(list.to.elbo(results_mat2n_a)$elbo)
flash(mat2n_a, prior.family=prior.point.exponential(), backfit=TRUE, verbose.lvl=0)$elbo
```

## Results: `X2n_b`

```{r, eval=FALSE}
# for record: g.pe <- gammamix(pi=c(0.1, 0.9), shape=c(1,1), scale=c(0,1))
out.list <- list()
data.mat <- mat2n_b

for (K in 1:8){
  print(paste0("now fitting K=",K)) 
  temp.list <- list()
  g.l <- rep(list(g.pe), K)
  g.f <- rep(list(g.pe), K)
      for (seed in 1:5){ 
        temp.list[[seed]] <- alt.flash(Y=data.mat, g.l=g.l, g.f=g.f, seed=seed)
        print(paste0("K=",K, "; seed=", seed, " completed"))
      }
  out.list[[K]] <- temp.list
}

saveRDS(out.list, "output/tree_toy_altflash_mat2n_b_v2021_1012_1309.rds")
```


```{r}
results_mat2n_b <- readRDS("output/tree_toy_altflash_mat2n_b_v2021_1012_1309.rds")
fig.elbo(results_mat2n_b)
fig.L(results_mat2n_b)
```

```{r}
max(list.to.elbo(results_mat2n_b)$elbo)
flash(mat2n_b, prior.family=prior.point.exponential(), backfit=TRUE, verbose.lvl=0)$elbo
```


## Check Symmetry

compare the scaled version of the two; all are identical

```{r}
fig.LF(results_mat2)
fig.LF(results_mat2n_a)
fig.LF(results_mat2n_b)
```




